{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Read the file train.csv into Python, Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('~\\\\SPICED\\\\train.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test splitting\n",
    "X = df.drop('Survived', axis=1)\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) #80% -> training, 20% ->testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    712\n",
       "Pclass         712\n",
       "Name           712\n",
       "Sex            712\n",
       "Age            572\n",
       "SibSp          712\n",
       "Parch          712\n",
       "Ticket         712\n",
       "Fare           712\n",
       "Cabin          159\n",
       "Embarked       710\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['S', 'C', 'Q', nan], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Embarked'].unique() # checking \"Embarked\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C124', nan, 'B58 B60', 'B38', 'C52', 'C93', 'C45', 'B20',\n",
       "       'B96 B98', 'C82', 'C78', 'C106', 'C22 C26', 'B57 B59 B63 B66',\n",
       "       'B28', 'C104', 'F2', 'D11', 'C86', 'E38', 'A34', 'C91', 'C68',\n",
       "       'F G73', 'E46', 'C92', 'E50', 'A32', 'G6', 'C128', 'E10', 'E44',\n",
       "       'B41', 'B18', 'D35', 'E31', 'C2', 'C50', 'C103', 'B3', 'A10',\n",
       "       'C49', 'C90', 'B77', 'C123', 'D', 'D36', 'E33', 'B5', 'A19', 'B37',\n",
       "       'E58', 'C23 C25 C27', 'F33', 'C7', 'E67', 'E8', 'B22', 'B35',\n",
       "       'C125', 'C65', 'C54', 'B80', 'B94', 'D26', 'E121', 'E24', 'D45',\n",
       "       'B101', 'B51 B53 B55', 'D17', 'D46', 'E17', 'B4', 'C46', 'A23',\n",
       "       'F4', 'C47', 'E101', 'C111', 'C101', 'B82 B84', 'C70', 'C32',\n",
       "       'B102', 'D20', 'B71', 'A36', 'D9', 'B50', 'D33', 'A16', 'B19',\n",
       "       'E12', 'C83', 'A26', 'F E69', 'A24', 'B73', 'C30', 'E40', 'D30',\n",
       "       'B42', 'C99', 'C85', 'D37', 'T', 'F38', 'C118', 'B49', 'B79', 'D6',\n",
       "       'F G63', 'A14', 'D49', 'C87', 'D56', 'C62 C64'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Cabin'].unique() # checking \"Cabin\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating functions by \"pipelining\" transformations for differenct columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a transformation pipeline for \"Age\": imputing + normalising\n",
    "impute_then_scale = make_pipeline(\n",
    "    SimpleImputer(strategy='mean'),\n",
    "    MinMaxScaler()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an alternative transformation pipeline for \"Age\": imputing + beaning + encoding\n",
    "impute_then_bin_then_encode = make_pipeline(\n",
    "    SimpleImputer(strategy='mean'),\n",
    "    KBinsDiscretizer(n_bins=7, encode='onehot-dense', strategy='uniform'),\n",
    "    OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a trasformation pipeline for \"Embarked\" with \"most frequent\" imputing strategy\n",
    "impute_then_encode_mf = make_pipeline(\n",
    "    SimpleImputer(strategy='most_frequent'),\n",
    "    OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an alternative trasformation pipeline for \"Embarked\" with \"Unknown\" imputing strategy\n",
    "impute_then_encode_unknown = make_pipeline(\n",
    "    SimpleImputer(strategy='constant', fill_value='Unknown'),\n",
    "    OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a trasformation pipeline for \"Cabin\"\n",
    "def get_initial(data):\n",
    "    '''cuts off the first letter from Cabin-code'''\n",
    "    return pd.DataFrame(data['Cabin'].str[0])\n",
    "\n",
    "encode_deck = make_pipeline(\n",
    "     FunctionTransformer(get_initial),\n",
    "     SimpleImputer(strategy='constant', fill_value='U'),\n",
    "     OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating total relatives feature and trasformation pipelines for that\n",
    "def total_relatives(data):\n",
    "    '''Calculates the sum of Siblings and Spouses Colimn and Parents and Children Column'''\n",
    "    new_data = data['SibSp'] + data['Parch']\n",
    "    return pd.DataFrame(new_data)\n",
    "\n",
    "total_relatives_scaled = make_pipeline(\n",
    "    FunctionTransformer(total_relatives),\n",
    "    MinMaxScaler(),\n",
    "    )\n",
    "\n",
    "total_relatives_encoded = make_pipeline(\n",
    "    FunctionTransformer(total_relatives),\n",
    "    OneHotEncoder(sparse=False, handle_unknown='ignore'),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating our ColumnTransformer\n",
    "fe = ColumnTransformer([\n",
    "    \n",
    "    # convert 'Passenger Class' and 'Sex' and|or 'SibSp' to binary columns\n",
    "    ('onehot', OneHotEncoder(sparse=False, handle_unknown='ignore'), ['Pclass', 'Sex', 'SibSp']),\n",
    "       \n",
    "    # fills the gaps in \"Age\" with median or mean, then do binning and encoding\n",
    "    ('impute and bin', impute_then_bin_then_encode, ['Age']),\n",
    "    \n",
    "    # fills the gaps in \"Age\" with median or mean, then normalizes it to 0.0 .. 1.0\n",
    "    #('impute and scale', impute_then_scale, ['Age']),\n",
    "    \n",
    "    # let's normalise 'SibSp' and|or 'Parch' and|or 'Fare'\n",
    "    #('scaler', MinMaxScaler(), ['Fare']),\n",
    "    \n",
    "    # let's normalise 'Total Relatives' Feature instead of 'SibSp' and 'Parch'\n",
    "    #('total_relatives_scaled', total_relatives_scaled, ['SibSp', 'Parch']),\n",
    "    \n",
    "    # let's normalise 'Total Relatives' Feature instead of 'SibSp' and 'Parch'\n",
    "    #('total_relatives_encoded', total_relatives_scaled, ['SibSp', 'Parch']),\n",
    "    \n",
    "    # let's normalise 'Fare'\n",
    "    #('scaler', MinMaxScaler(), ['Fare']),\n",
    "    \n",
    "    # let's deal with the cabin ATTENTION! - this probably overfits the model\n",
    "    ('get deck and encode', encode_deck, ['Cabin']),\n",
    "    \n",
    "    # fills the gaps in \"Embarked\" with most frequent, then convert it to binary columns\n",
    "    ('impute and encode', impute_then_encode_mf, ['Embarked']),\n",
    "    \n",
    "    # fills the gaps in \"Embarked\" with most frequent, then convert it to binary columns\n",
    "    #('impute and encode', impute_then_encode_Unknown, ['Embarked']),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and applying our Column Transformer\n",
    "fe.fit(X_train)\n",
    "X_train_trans = fe.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "        1.        , 0.        , 1.        , 0.        , 1.        ,\n",
       "        0.        , 0.        , 1.        , 1.        , 0.        ,\n",
       "        1.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "        0.        , 0.0556283 , 0.        , 0.        , 1.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 1.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        , 1.        ,\n",
       "        1.        , 0.        , 0.        , 1.        , 1.        ,\n",
       "        0.        , 1.        , 0.        , 1.        , 0.        ,\n",
       "        1.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "        0.        , 0.02537431, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.        , 0.        , 0.        , 1.        ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_trans[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Create and Fit our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. create a model (with parameters not fitted)\n",
    "model = LogisticRegression()\n",
    "# 2. train with transformed training data\n",
    "model.fit(X_train_trans, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation scores [0.7972028  0.82517483 0.82394366 0.76056338 0.83802817]\n"
     ]
    }
   ],
   "source": [
    "accuracy = cross_val_score(model, X_train_trans, y_train, cv=5, scoring='accuracy')\n",
    "print(\"cross-validation scores\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 - Bootstraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "boots = []\n",
    "for i in range(1000):\n",
    "    # Resampling the original data to create a \"new\" dataset\n",
    "    Xb, yb = resample(X_train_trans, y_train)\n",
    "    \n",
    "    b = round(0.8 * (Xb.shape[0]))\n",
    "    \n",
    "    # Splitting the data into training and validation set\n",
    "    Xb_train = Xb[:b]\n",
    "    yb_train = yb[:b]\n",
    "    Xb_validation = Xb[b:]\n",
    "    yb_validation = yb[b:]\n",
    "\n",
    "    # Fitting the model and calculate the validation score\n",
    "    model.fit(Xb_train, yb_train)\n",
    "    score = model.score(Xb_validation, yb_validation)\n",
    "    boots.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x0000022F200EF2B0>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "boots_df = pd.DataFrame(boots)\n",
    "boots_df.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.815007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.033390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.711268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.795775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.816901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.838028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.915493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  1000.000000\n",
       "mean      0.815007\n",
       "std       0.033390\n",
       "min       0.711268\n",
       "25%       0.795775\n",
       "50%       0.816901\n",
       "75%       0.838028\n",
       "max       0.915493"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boots_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7 - Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.815"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(model.score(X_train_trans, y_train), 3)  # --> train accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming the test data\n",
    "X_test_trans = fe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.827"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(model.score(X_test_trans, y_test), 3)  # --> test accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8 - Getting results for kaggle.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model on the whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe.fit(X)\n",
    "X_trans = fe.transform(X)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_trans, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.825"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(model.score(X_trans, y), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('~\\\\SPICED\\\\test.csv')\n",
    "test_trans = fe.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived\n",
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(test_trans)\n",
    "pd.DataFrame({'Survived': prediction}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame()\n",
    "result['PassengerId'] = test['PassengerId']\n",
    "result['Survived'] = pd.DataFrame({'Survived': prediction})['Survived']\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('results_logistic_regression.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle Results for this model: 0.77511, which is in top-10.000 of all submissions =)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
